{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0da0a788",
   "metadata": {},
   "source": [
    "# Create size error plot with selected scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f57964",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fd4bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots, DelimitedFiles, DataFrames, CSV\n",
    "import YAML\n",
    "\n",
    "gr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468df59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create readers for data loading.\n",
    "include(\"datareader.jl\")\n",
    "\n",
    "rundir = \"/home/ebr/projects/tsunami-inundation-emulator/article_runs/t591/mc8_l8_rel/\"  \n",
    "eval_dir = joinpath(rundir, \"evaluation/test\")\n",
    "preds_dir = joinpath(rundir, \"evaluation/preds\")\n",
    "#eval_dir = joinpath(rundir, \"evaluation\", \"test_40000\")\n",
    "config = DataReader.parse_config(joinpath(rundir, \"config.yml\"))\n",
    "#evaluation_scenarios = config[\"test_data\"]\n",
    "#reader = DataReader.Reader(config)\n",
    "\n",
    "# Create evaluation directory\n",
    "if !isdir(preds_dir)\n",
    "    mkpath(preds_dir)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01e7563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load output as dataframe.\n",
    "df = CSV.File(joinpath(eval_dir, \"summary_results.txt\"); delim='\\t') |> DataFrame;\n",
    "unique!(df, :scenario)\n",
    "# sort!(test_df, [:error]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc37844a",
   "metadata": {},
   "outputs": [],
   "source": [
    "names(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29d5cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort!(df, :l2_norm);\n",
    "\n",
    "df.log2_l2norm = log2.(df.l2_norm);\n",
    "\n",
    "nbins = 20\n",
    "max_samples_per_bin = 1\n",
    "\n",
    "h = fit(Histogram, df.log2_l2norm, nbins=nbins)\n",
    "\n",
    "\n",
    "df[!, :selected] = falses(size(df)[1]);\n",
    "#df = df[shuffle(1:size(df, 1)),:] # Random selection\n",
    "\n",
    "bounds = prepend!(cumsum(h.weights),1)\n",
    "for i in 1:length(h.weights)\n",
    "    nr_of_samples = min(max_samples_per_bin, h.weights[i]+1)\n",
    "    rows = sample(bounds[i]:bounds[i+1], nr_of_samples; replace = false, ordered = true)\n",
    "    df.selected[rows] = trues(nr_of_samples)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337d2ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = plot(h, label=\"Total\", ylabel=\"Nr. of scenarios\", yaxis = (:log10, (1,Inf)), alpha=0.2)\n",
    "p = histogram!(p, df[df.selected .== true,:log2_l2norm], label=\"Selected\", nbins=nbins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7d6bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.selected .== true,:scenario]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689852ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write selected scenarios to file.\n",
    "\n",
    "open(joinpath(preds_dir,\"selected_scenarios.txt\"), \"w\") do io\n",
    "    writedlm(io, df[df.selected .== true,:scenario])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aa1073",
   "metadata": {},
   "source": [
    "## Scatter plot with scenario labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4230838b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p = scatter(\n",
    "    df[df.selected .== false, :l2_norm], \n",
    "    df[df.selected .== false, :l2_err], \n",
    "    scale = :log10, \n",
    "    xlabel=\"\\$\\\\ell^2\\$-norm\", \n",
    "    ylabel=\"\\$\\\\ell^2\\$-error\", \n",
    "    label = false, \n",
    "    markershape=:circle,\n",
    "    markersize = 1.5,\n",
    "    minorgrid = true,\n",
    "    alpha=0.2,\n",
    "    legend=:topleft,\n",
    "    ylims=(1e-3,0),\n",
    "    xlims=(1e-3,0),\n",
    "    ticks=[1e-2,1e-1,1],\n",
    "    dpi=300,\n",
    "    aspect_ratio = 1.,\n",
    ")\n",
    "\n",
    "p = @df df[df.selected .== true,:] scatter!(\n",
    "    p, \n",
    "    :l2_norm,\n",
    "    :l2_err,\n",
    "    alpha=0.5,\n",
    "    label=false,\n",
    "    marker = (14, 0.3, :orange)\n",
    ") \n",
    "@df df[df.selected .== true,:] annotate!(\n",
    "    p, \n",
    "    :l2_norm, \n",
    "    :l2_err,\n",
    "    [text(\"$i\", 8, :center) for i in 1:sum(df.selected .== true)]\n",
    ")\n",
    "\n",
    "plot!(p, [1e-3,1],[1e-3,1], linestyle=:dash, linewidth=3, linecolor=:grey, label=\"\")\n",
    "savefig(joinpath(preds_dir, \"size-error-scatter-selected.png\"))\n",
    "display(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291fff3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run predict.jl on selected_scenarios.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6a9152",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29d2f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"julia --project predict.jl $(rundir) $(joinpath(preds_dir,\"selected_scenarios.txt\")) --output-dir $(preds_dir)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b18a149",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
