{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "478c6343",
   "metadata": {},
   "source": [
    "This notebook is intended for visualizing statistics associated with the comparisson of multiple models. The input is summary statistics in the form of a json file, containing a dictionary with stats for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e4c87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "using JSON, DataFrames, StatsPlots, Measures, CSV\n",
    "\n",
    "gr()\n",
    "theme(:ggplot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cb5bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_list = JSON.parsefile(\"article_runs/stats.json\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec48351f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0abcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_model_features_from_path(path)\n",
    "    pathlist = split(path, '/')\n",
    "    features = Dict(\n",
    "        \"training_set\" => parse(Int64, split(pathlist[end-3][2:end], \"_\")[1]),\n",
    "        \"model_name\" => String(pathlist[end-2]),\n",
    "        \"evaluation_set\" => String(pathlist[end])\n",
    "    )\n",
    "end\n",
    "\n",
    "out_dir = \"/home/ebr/projects/tsunami-inundation-emulator/article_runs/figures\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd23f9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_stats in stats_list\n",
    "    model_stats[\"features\"] = get_model_features_from_path(model_stats[\"eval_dir\"])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54f454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98b55e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = DataFrame(\n",
    "    evaluation_set = [model_stats[\"features\"][\"evaluation_set\"] for model_stats in stats_list],\n",
    "    training_set = [model_stats[\"features\"][\"training_set\"] for model_stats in stats_list],\n",
    "    model = [model_stats[\"features\"][\"model_name\"] for model_stats in stats_list],\n",
    "    q95_l2 =[model_stats[\"stats\"][\"q95_l2\"] for model_stats in stats_list],\n",
    "    mean_l2 =[model_stats[\"stats\"][\"mean_l2\"] for model_stats in stats_list],\n",
    "    aida_K_q95 =[model_stats[\"stats\"][\"aida_K_q95\"] for model_stats in stats_list],\n",
    "    std_res_q95 =[model_stats[\"stats\"][\"std_res_q95\"] for model_stats in stats_list],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5a343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = DataFrame(\n",
    "    evaluation_set = [model_stats[\"features\"][\"evaluation_set\"] for model_stats in stats_list],\n",
    "    training_set = [model_stats[\"features\"][\"training_set\"] for model_stats in stats_list],\n",
    "    model = [model_stats[\"features\"][\"model_name\"] for model_stats in stats_list]\n",
    ");\n",
    "\n",
    "df_stats = DataFrame([Symbol(c) => [model_stats[\"stats\"][c] for model_stats in stats_list] for c in keys(stats_list[1][\"stats\"])]);\n",
    "\n",
    "df = hcat(df_features, df_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcb829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = sort(df[df.evaluation_set .== \"test\", [:model, :training_set, :mean_l2, :q95_l2]], :q95_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359823fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = groupby(df_test, :model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67490d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = gdf[3] \n",
    "#tdf[!, :id] = 1:size(tdf, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2009c6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = [:model, :mean_l2, :q95_l2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fe5099",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6c34e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf[1,:model] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c87dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = stack(tdf,  [:mean_l2, :q95_l2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ffb1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "unstack(sdf, :training_set, :value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdb5a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0820956",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dfs = []\n",
    "for tdf in gdf\n",
    "    colnames = names(tdf)\n",
    "    #tdf[!, :id] = 1:size(tdf, 1)\n",
    "    sdf = stack(tdf,  [:mean_l2, :q95_l2])\n",
    "    if tdf[1,:model] in [\"mc32_l16_rel_reg\", \"mc8_l8_rel\", \"mc32_l16_rel_reg\"]\n",
    "        push!(res_dfs, unstack(sdf, :training_set, :value))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb59a4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dfs = []\n",
    "for tdf in gdf\n",
    "    colnames = names(tdf)\n",
    "    tdf[!, :id] = 1:size(tdf, 1)\n",
    "    sdf = stack(tdf,  [:training_set, :mean_l2, :q95_l2])\n",
    "    push!(res_dfs, unstack(sdf, :id, :value))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f08aa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = vcat(res_dfs..., cols=:union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdadd36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show(scores, allrows=true, allcols=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d540b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV.write(joinpath(out_dir, \"df_score_stats.csv\"), scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1cdd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort(df[df.evaluation_set .== \"test\" .&& df.training_set .== 295,:], :q95_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6ddf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort(df[df.evaluation_set .== \"test\" .&& df.training_set .== 591,:], :q95_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb52bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort(df[df.evaluation_set .== \"test\" .&& df.training_set .== 1831,:], :q95_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf069dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort!(df, [:training_set])\n",
    "\n",
    "p1 = @df df[df.evaluation_set .== \"test\" .&& (df.model .== \"mc8_l8\" .|| df.model .== \"mc32_l16\" .|| df.model .== \"mc32_l16_rel\" .|| df.model .== \"mc8_l8_rel\"), :] plot(\n",
    "    :training_set,\n",
    "    :mean_l2,\n",
    "    group = :model,\n",
    "    xscale = :log10,\n",
    "    xlim = (100, 5000),\n",
    "    ylim = (0.015, 0.045),\n",
    "    ylabel = \"Mean \\$\\\\ell^2\\$-error\", \n",
    "    xlabel = \"Size of training set\",\n",
    "    m = (0.5, [:sq :h :d :star7 :c :star5], 10),\n",
    "    margin = 5mm\n",
    ")\n",
    "\n",
    "p2 = @df df[df.evaluation_set .== \"train\" .&& (df.model .== \"mc8_l8\" .|| df.model .== \"mc32_l16\" .|| df.model .== \"mc32_l16_rel\" .|| df.model .== \"mc8_l8_rel\"), :] plot(\n",
    "    :training_set,\n",
    "    :mean_l2,\n",
    "    group = :model,\n",
    "    xscale = :log10,\n",
    "    xlim = (100, 5000),\n",
    "    ylim = (0.015, 0.045),\n",
    "    #ylabel = \"95% quantile of \\$\\\\ell^2\\$-error\", \n",
    "    xlabel = \"Size of training set\",\n",
    "    m = (0.5, [:sq :h :d :star7 :c :star5], 10),\n",
    "    margin = 5mm\n",
    ")\n",
    "\n",
    "p = plot(p1, p2, layout = (1,2), size=(900,400), title=[\"Test\" \"Train\"])\n",
    "savefig(p, joinpath(out_dir, \"compare_mean_l2.svg\"))\n",
    "display(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93236dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = @df df[df.evaluation_set .== \"test\" .&& (df.model .== \"mc8_l8\" .|| df.model .== \"mc32_l16\" .|| df.model .== \"mc8_l8_rel\" .|| df.model .== \"mc32_l16_rel\"), :] plot(\n",
    "    :training_set,\n",
    "    :aida_K_q50,\n",
    "    group = :model,\n",
    "    xscale = :log10,\n",
    "    xlim = (100, 5000),\n",
    "    m = (0.5, [:sq :h :d :star7 :c :star5], 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51da3250",
   "metadata": {},
   "outputs": [],
   "source": [
    "@df df[df.evaluation_set .== \"test\", :] scatter(\n",
    "    :training_set,\n",
    "    :q95_l2,\n",
    "    group = :model,\n",
    "    xscale = :log10,\n",
    "    xlim = (100, 5000),\n",
    "    m = (0.5, [:sq :h :d :star7 :c :star5], 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9e0877",
   "metadata": {},
   "outputs": [],
   "source": [
    "@df df[df.evaluation_set .== \"train\", :] scatter(\n",
    "    :training_set,\n",
    "    :q95_l2,\n",
    "    group = :model,\n",
    "    xscale = :log10,\n",
    "    xlim = (100, 5000),\n",
    "    m = (0.5, [:sq :h :d :star7 :c :star5], 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb32a245",
   "metadata": {},
   "outputs": [],
   "source": [
    "@df df[df.evaluation_set .== \"test\", :] scatter(\n",
    "    :training_set,\n",
    "    :std_res_q95,\n",
    "    group = :model,\n",
    "    xscale = :log10,\n",
    "    xlim = (100, 5000),\n",
    "    m = (0.5, [:sq :h :d :star7 :c :star5], 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ca04f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort!(df[df.evaluation_set .== \"test\",:], :mean_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f06430",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"hald\"[2:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bbe37d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
